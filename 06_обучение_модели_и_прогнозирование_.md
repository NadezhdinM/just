---
 title: 'Обучение модели и прогнозирование'
 layout: home
---

# Chapter 6: Обучение модели и прогнозирование


В [предыдущей главе](05_скользящее_среднее__ema__для_формы_игрока_.html) мы научились рассчитывать экспоненциальное скользящее среднее (EMA), чтобы получить сглаженную оценку текущей формы игроков по различным показателям (подача, прием, производительность). Теперь, когда у нас есть богатый набор признаков, описывающих игроков и матчи (рейтинги [ELO](02_расчет_рейтинга_elo_.html), [PCA-рейтинги](03_создание_признаков_и_pca_.html), [оценка производительности и H2H](04_оценка_производительности_и_h2h_.html), EMA-показатели, возраст и т.д.), мы подошли к самому сердцу нашего проекта — использованию машинного обучения для предсказания исходов теннисных матчей.

**Проблема:** У нас есть много данных о прошлых матчах и характеристиках игроков, но как научить компьютер автоматически находить в этих данных закономерности и использовать их для прогнозирования того, кто победит в будущем матче?

**Цель этой главы:** Понять основы машинного обучения в контексте нашего проекта, научиться подготавливать данные для модели, обучать модель логистической регрессии, оценивать ее качество и, наконец, получать от нее прогнозы в виде вероятностей победы.

Представьте, что вы хотите научить компьютер играть в шахматы, показывая ему тысячи партий. Компьютер анализирует эти партии, выявляет выигрышные и проигрышные стратегии и со временем учится делать сильные ходы. В нашем случае "партии" — это прошлые теннисные матчи, а "ходы" — это прогнозы на будущие игры.

## Ключевые концепции машинного обучения

Прежде чем погрузиться в код, давайте разберемся с несколькими важными терминами:

1.  **Машинное обучение (Machine Learning):** Это область искусственного интеллекта, где компьютеры "учатся" на данных без явного программирования для каждой задачи. Модель сама находит скрытые паттерны.
2.  **Признаки (Features):** Это входные данные для модели — характеристики, которые мы подготовили на предыдущих этапах. В нашем случае это разница в ELO (`delta_elo`), разница в EMA подачи (`delta_service`), баланс личных встреч (`hth_1`), разница в возрасте (`delta_age`) и т.д. Это та информация, на основе которой модель будет делать прогноз.
3.  **Целевая переменная (Target Variable):** Это то, что мы хотим предсказать. В нашем проекте это исход матча — победил ли игрок 1 (`player_1_v = 1`) или проиграл (`player_1_v = 0`). Модель учится предсказывать значение этой переменной на основе признаков.
4.  **Модель (Model):** Это математический "движок", который обучается на данных. В нашем проекте мы используем **Логистическую Регрессию**. Это хороший выбор для задач *бинарной классификации* (когда есть два возможных исхода, как победа/поражение), потому что она не просто предсказывает класс (0 или 1), но и выдает *вероятность* принадлежности к этому классу (например, вероятность победы игрока 1 равна 0.7).
5.  **Обучение (Training):** Процесс "скармливания" модели большого количества примеров (прошлых матчей) с известными признаками и результатами (целевой переменной). Модель подстраивает свои внутренние параметры, чтобы как можно точнее предсказывать результат на основе признаков.
6.  **Разделение данных (Train/Test Split):** Очень важно не использовать все данные для обучения. Мы делим наш набор данных на две части:
    *   **Обучающая выборка (Training Set):** Большая часть данных (например, 70%), на которой модель учится.
    *   **Тестовая выборка (Test Set):** Меньшая часть данных (например, 30%), которую модель *не видела* во время обучения. Она используется для проверки того, насколько хорошо обученная модель работает на новых, незнакомых данных. Это помогает понять, не "вызубрила" ли модель обучающие данные вместо того, чтобы найти общие закономерности. В нашем проекте важно делать разделение по времени: обучаемся на более старых матчах, тестируем на более новых.
7.  **Оценка (Evaluation):** После обучения мы проверяем модель на тестовой выборке и смотрим, насколько ее прогнозы совпадают с реальными результатами. Для этого используются разные метрики:
    *   **Точность (Accuracy):** Доля правильных прогнозов (угаданных исходов).
    *   **Log Loss (Логарифмическая функция потерь):** Метрика, которая штрафует модель не только за неправильный прогноз, но и за неуверенность в правильном прогнозе. Особенно важна для вероятностных моделей. Чем ниже Log Loss, тем лучше.
    *   **Precision, Recall, F1-score:** Метрики, показывающие точность модели для каждого класса (победа/поражение) и баланс между ними.
    *   **ROC AUC:** Показывает, насколько хорошо модель умеет различать классы (победителей и проигравших).
8.  **Подбор гиперпараметров (Hyperparameter Tuning):** У моделей машинного обучения есть настройки (гиперпараметры), которые мы задаем *до* начала обучения (например, сила регуляризации `alpha` в логистической регрессии). Подбор оптимальных гиперпараметров — это процесс поиска таких настроек, при которых модель показывает наилучшее качество на тестовых (или валидационных) данных. Мы будем использовать `RandomizedSearchCV` для автоматического подбора.

## Процесс обучения и прогнозирования (на примере `Training.py`)

Давайте посмотрим, как эти концепции реализуются в коде. Мы будем использовать скрипт `Training.py`.

### 1. Загрузка и подготовка данных

Сначала загружаем DataFrame, содержащий все рассчитанные нами признаки из предыдущих глав (`final_df2.csv`).

```python
import pandas as pd

# Загружаем данные с рассчитанными признаками
matches_df = pd.read_csv('final_df2.csv')

# Посмотрим на доступные колонки
print(list(matches_df.columns))
```

Затем выбираем только те столбцы, которые будут использоваться как признаки для модели, а также целевую переменную (`player_1_v`).

```python
# Выбираем нужные колонки для моделирования
df = matches_df[[
    'player_1_v', # Наша целевая переменная (1 - игрок 1 победил, 0 - проиграл)
    'court_surface', # Покрытие (пока не используется напрямую, но может быть полезно)
    'start_date', # Дата (для разделения на обучение/тест)
    'player_id', 'opponent_id', # ID игроков (для информации)
    'elo_1_surface', 'elo_2_surface', # ELO на покрытии до матча
    'elo_1', 'elo_2', # Общий ELO до матча
    'service_pca_1_ema', 'service_pca_2_ema', # EMA PCA подачи
    'return_pca_1_ema', 'return_pca_2_ema', # EMA PCA приема
    'hth_1', 'hth_2', # Баланс H2H до матча
    'performance_1_ema', 'performance_2_ema', # EMA оценки производительности
    'player age', 'opponent age', # Возраст игроков
    'errors_pca_1_ema', 'errors_pca_2_ema' # EMA PCA ошибок на подаче
]].copy()

print("Выбранные данные:")
print(df.head())
```

### 2. Создание "Дельта"-признаков

Часто модели лучше работают не с абсолютными значениями признаков для каждого игрока, а с их **разницей**. Например, модели важнее знать не `elo_1` и `elo_2` по отдельности, а `elo_1 - elo_2`. Это напрямую показывает относительную силу игроков.

```python
# Рассчитываем разницы между признаками игрока 1 и игрока 2
df['delta_elo_surface'] = df['elo_1_surface'] - df['elo_2_surface']
df['delta_elo'] = df['elo_1'] - df['elo_2']
df['delta_service'] = df['service_pca_1_ema'] - df['service_pca_2_ema']
df['delta_return'] = df['return_pca_1_ema'] - df['return_pca_2_ema']
df['delta_performance'] = df['performance_1_ema'] - df['performance_2_ema']
df['delta_service_mistakes'] = df['errors_pca_1_ema'] - df['errors_pca_2_ema']
df['delta_age'] = df['player age'] - df['opponent age']
# Используем hth_1 напрямую, так как он уже отражает разницу

print("Данные с 'дельта'-признаками:")
print(df[['delta_elo', 'delta_service', 'hth_1']].head())
```

### 3. Очистка и финальный выбор признаков

Удаляем строки с пропущенными значениями (`NaN`), которые могли возникнуть на этапах расчета признаков, и оставляем только целевую переменную и финальные "дельта"-признаки.

```python
# Удаляем строки, где хотя бы один из ключевых признаков отсутствует
key_features = ['delta_elo_surface','delta_elo','delta_service','delta_return',
                'delta_performance','delta_service_mistakes','delta_age','hth_1']
df.dropna(inplace = True, subset=key_features)

# Оставляем только целевую переменную и 8 финальных признаков
df = df[['player_1_v'] + key_features]

print(f"Осталось {len(df)} матчей после очистки.")
print("Финальный набор признаков для модели:")
print(df.head())
# df.to_csv('final_df3.csv') # Сохраняем финальный датасет для модели
```

### 4. Разделение на обучающую и тестовую выборки

Разделяем данные на те, на которых будем обучать модель (train), и те, на которых будем ее проверять (test). Важно сделать это по времени: берем первые 70% данных (самые старые матчи) для обучения, а последние 30% (самые новые) — для теста. Это имитирует реальную ситуацию, когда мы прогнозируем будущие матчи на основе прошлых.

```python
# Определяем точку разделения (70% данных)
split_index = int(len(df) * 0.7)

# Создаем обучающий набор (X_train, y_train)
x_train = df.iloc[0:split_index][key_features] # Признаки для обучения
y_train = df.iloc[0:split_index]['player_1_v'] # Результаты для обучения

# Создаем тестовый набор (X_test, y_test)
x_test = df.iloc[split_index:][key_features]   # Признаки для теста
y_test = df.iloc[split_index:]['player_1_v']   # Результаты для теста

print(f"Размер обучающей выборки: {len(x_train)} матчей")
print(f"Размер тестовой выборки: {len(x_test)} матчей")
```

### 5. Масштабирование признаков

Признаки имеют разный масштаб (например, `delta_elo` может быть сотнями, а `delta_service` - единицами). Чтобы модель не придавала необоснованно большой вес признакам с большими значениями, мы приводим их к одному масштабу с помощью `StandardScaler`. Он преобразует данные так, чтобы у каждого признака среднее значение было 0, а стандартное отклонение - 1.

**Важно:** `StandardScaler` обучается (`fit`) *только* на обучающих данных (`x_train`), а затем применяется (`transform`) и к обучающим, и к тестовым данным (`x_test`). Это предотвращает "утечку" информации из тестовой выборки в процесс обучения.

```python
from sklearn.preprocessing import StandardScaler

# Создаем объект StandardScaler
scaler = StandardScaler()

# Обучаем scaler на обучающих данных и преобразуем их
x_train_scaled = scaler.fit_transform(x_train)

# Преобразуем тестовые данные, используя тот же обученный scaler
x_test_scaled = scaler.transform(x_test)

print("Пример масштабированных данных (первые 5 строк x_train):")
# Преобразуем обратно в DataFrame для наглядности (не обязательно)
# df_scaled_train = pd.DataFrame(x_train_scaled, columns=key_features)
# print(df_scaled_train.head())
print(x_train_scaled[:5, :3]) # Показываем первые 3 признака первых 5 матчей
```

### 6. Определение и обучение модели (с подбором гиперпараметров)

Мы будем использовать `SGDClassifier` с параметром `loss="log"`. Это реализация логистической регрессии, которая обучается с помощью стохастического градиентного спуска (эффективно для больших данных).

У `SGDClassifier` есть важный гиперпараметр `alpha`, который контролирует силу регуляризации (механизм для предотвращения переобучения). Мы не знаем заранее, какое значение `alpha` будет лучшим. Поэтому используем `RandomizedSearchCV`:
*   Он пробует несколько случайных значений `alpha` из заданного диапазона (`param_dist`).
*   Для каждого значения он проводит **кросс-валидацию** (`cv=KFold(30)`): делит *обучающую* выборку на 30 частей, 29 использует для обучения, 1 для проверки, и так 30 раз, чтобы получить надежную оценку качества для данного `alpha`.
*   В итоге он выбирает то значение `alpha`, которое показало наилучший средний результат на кросс-валидации.

```python
import numpy as np
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import RandomizedSearchCV, KFold

# 1. Определяем модель (Логистическая регрессия через SGD)
# loss="log" - включает логистическую регрессию
# fit_intercept=False - предполагаем, что данные центрированы (StandardScaler)
# max_iter=1000 - максимальное число проходов по данным
# shuffle=False - не перемешивать данные (важно для SGD с early_stopping)
# verbose=1 - показывать прогресс обучения
# early_stopping=True - останавливать обучение, если качество на валидации перестает улучшаться
# n_iter_no_change=25 - сколько эпох ждать улучшения перед остановкой
# tol=0.000001 - критерий остановки
clf = SGDClassifier(loss="log", fit_intercept=False, max_iter=1000, shuffle=False,
                    verbose=0, # Установим 0 для краткости вывода
                    early_stopping=True, n_iter_no_change=25, tol=0.000001)

# 2. Задаем диапазон для подбора гиперпараметра alpha
# Пробуем значения 1e-1, 1e-2, ..., 1e-6
param_dist = {'alpha': 10.0**-np.arange(1, 7)}

# 3. Настраиваем RandomizedSearchCV
# estimator=clf - модель, которую настраиваем
# param_distributions=param_dist - откуда брать значения alpha
# return_train_score=True - сохранять результаты на обучении
# n_iter=6 - сколько разных alpha попробовать (все 6 из нашего списка)
# cv=KFold(30) - 30-кратная кросс-валидация
# verbose=1 - показывать прогресс подбора
rsh = RandomizedSearchCV(estimator=clf, param_distributions=param_dist,
                         return_train_score=True, n_iter=6, cv=KFold(30), verbose=1)

# 4. Запускаем обучение и подбор гиперпараметров
# Используем масштабированные обучающие данные
rsh.fit(x_train_scaled, y_train)

# 5. Получаем лучшую найденную модель
best_model = rsh.best_estimator_
print(f"\nЛучшая модель найдена: {best_model}")
print(f"Лучшее значение alpha: {best_model.alpha}")
```

### 7. Оценка качества лучшей модели

Теперь, когда у нас есть `best_model` (логистическая регрессия с оптимальным `alpha`), мы оцениваем ее на *тестовой* выборке (`x_test_scaled`, `y_test`), которую модель еще не видела.

```python
from sklearn.metrics import classification_report, accuracy_score, log_loss, roc_auc_score

# Делаем предсказания на тестовых данных
y_pred = best_model.predict(x_test_scaled)
y_pred_proba = best_model.predict_proba(x_test_scaled)[:, 1] # Вероятность победы игрока 1

# Рассчитываем метрики
accuracy = accuracy_score(y_test, y_pred)
logloss = log_loss(y_test, y_pred_proba) # Используем вероятности для logloss
roc_auc = roc_auc_score(y_test, y_pred_proba) # Используем вероятности для ROC AUC

print("\n--- Оценка модели на тестовых данных ---")
print(f"Точность (Accuracy): {accuracy:.4f}")
print(f"Log Loss: {logloss:.4f}")
print(f"ROC AUC: {roc_auc:.4f}")

# Подробный отчет по классам (Precision, Recall, F1)
print("\nОтчет по классификации:")
# target_names=['Проигрыш P1', 'Победа P1'] можно добавить для понятности
print(classification_report(y_test, y_pred))
```

**Интерпретация метрик:**
*   **Accuracy (Точность):** Около 0.66-0.68 (в зависимости от запуска и данных) — означает, что модель правильно угадывает исход примерно в 66-68% случаев. Это значительно лучше случайного угадывания (50%).
*   **Log Loss:** Обычно в районе 0.60-0.62. Чем ниже, тем лучше модель оценивает вероятности.
*   **ROC AUC:** Обычно около 0.71-0.73. Значение выше 0.5 говорит о том, что модель умеет различать классы лучше, чем случайное угадывание. Значение 0.7-0.8 считается хорошим для такой сложной задачи.
*   **Classification Report:** Показывает `precision` (доля правильных позитивных прогнозов из всех позитивных) и `recall` (доля найденных позитивных прогнозов из всех реальных позитивных) для каждого класса (0 - проигрыш игрока 1, 1 - победа игрока 1). `F1-score` - их гармоническое среднее.

### 8. Интерпретация модели: Какие признаки важнее?

Логистическая регрессия — относительно "прозрачная" модель. Мы можем посмотреть на ее коэффициенты (`coef_`), чтобы понять, как каждый признак влияет на прогноз.

```python
import matplotlib.pyplot as plt
import math

# Получаем коэффициенты модели
coefficients = best_model.coef_[0]
feature_names = key_features # Наши 'дельта'-признаки

# Создаем DataFrame для удобства
coef_df = pd.DataFrame({'Признак': feature_names, 'Коэффициент': coefficients})
coef_df = coef_df.sort_values(by='Коэффициент', ascending=False)

# Рассчитываем Odds Ratio (отношение шансов) = exp(коэффициент)
# Показывает, во сколько раз увеличиваются шансы на победу игрока 1
# при увеличении признака на 1 единицу (стандартного отклонения, т.к. данные масштабированы)
coef_df['Odds Ratio'] = coef_df['Коэффициент'].apply(math.exp)

print("\n--- Влияние признаков на прогноз (Коэффициенты и Odds Ratio) ---")
print(coef_df)

# Визуализация коэффициентов
plt.figure(figsize=(8, 6))
plt.barh(coef_df['Признак'], coef_df['Коэффициент'])
plt.xlabel('Вес коэффициента')
plt.title('Важность признаков в модели Логистической Регрессии')
plt.gca().invert_yaxis() # Показать самый важный признак сверху
plt.show()
```

**Интерпретация коэффициентов:**
*   **Положительный коэффициент:** Увеличение этого признака повышает вероятность победы игрока 1. Например, `delta_elo` (разница в общем ELO) и `delta_elo_surface` (разница ELO на покрытии) обычно имеют самые большие положительные веса, что логично — чем выше рейтинг игрока 1 по сравнению с игроком 2, тем выше его шансы. `delta_service` (разница в качестве подачи) тоже обычно положительна.
*   **Отрицательный коэффициент:** Увеличение этого признака *уменьшает* вероятность победы игрока 1. Например, `delta_performance` (разница в EMA производительности) может иметь отрицательный вес. Это может показаться контринтуитивным, но нужно помнить, что `performance_1_ema` - это *отклонение от ожиданий*. Возможно, модель находит, что игроки, чья производительность *сильно превосходила* ожидания (высокий `performance_ema`), в следующих матчах показывают результат ближе к среднему ("регрессия к среднему"). `delta_service_mistakes` (разница в ошибках на подаче) также логично имеет отрицательный вес (больше ошибок -> меньше шансов).
*   **Нулевой или близкий к нулю коэффициент:** Признак почти не влияет на прогноз (например, `delta_age` или `delta_return` могут иметь небольшие веса).
*   **Odds Ratio > 1:** Увеличение признака увеличивает шансы на победу.
*   **Odds Ratio < 1:** Увеличение признака уменьшает шансы на победу.

**Примечание:** В скрипте `Training.py` также используется библиотека `shap` для более глубокого анализа важности признаков (SHAP values, beeswarm plot). Это более продвинутая техника, которая показывает вклад каждого признака в *каждый конкретный* прогноз.

### 9. Получение прогнозов (вероятностей)

Наконец, мы используем обученную модель, чтобы получить вероятности победы для матчей из тестовой выборки.

```python
# Получаем вероятности для обоих классов (0 и 1)
probabilities = best_model.predict_proba(x_test_scaled)

# Вероятность победы игрока 1 (класс 1)
proba_player1_wins = probabilities[:, 1]

# Вероятность победы игрока 2 (класс 0)
proba_player2_wins = probabilities[:, 0]

# Добавим вероятности к нашему тестовому DataFrame для наглядности
x_test_results = x_test.copy() # Копируем исходные (немасштабированные) признаки теста
x_test_results['Истинный исход (P1)'] = y_test.values
x_test_results['Прогноз модели (P1)'] = y_pred
x_test_results['Вероятность победы P1'] = proba_player1_wins
x_test_results['Вероятность победы P2'] = proba_player2_wins

print("\n--- Примеры прогнозов на тестовых данных ---")
print(x_test_results[['Истинный исход (P1)', 'Прогноз модели (P1)', 'Вероятность победы P1']].head())
```

Эти вероятности (`Вероятность победы P1`) — главный результат работы нашей модели. Именно их мы будем использовать в следующей главе для симуляции ставок.

## Общая схема обучения и прогнозирования

```mermaid
graph TD
    A[Подготовленные данные (final_df2.csv)] --> B(Выбор признаков и целевой переменной);
    B --> C(Создание 'Дельта'-признаков);
    C --> D(Очистка NaN);
    D --> E{Разделение данных (Train/Test по времени)};
    E -- Обучающая выборка --> F(Масштабирование Scaler.fit_transform(X_train));
    E -- Тестовая выборка --> G(Масштабирование Scaler.transform(X_test));
    F -- Масштаб. X_train, y_train --> H{Подбор гиперпараметров (RandomizedSearchCV + KFold)};
    H --> I(Обучение лучшей модели SGDClassifier);
    I -- Обученная модель --> J(Оценка на тест. данных X_test_scaled, y_test);
    J --> K[Метрики качества (Accuracy, LogLoss, ROC AUC)];
    I -- Обученная модель --> L(Интерпретация: Коэффициенты, SHAP);
    I -- Обученная модель --> M(Прогнозирование вероятностей predict_proba(X_test_scaled));
    M --> N[Вероятности исходов матчей];

    subgraph "Подготовка данных"
        direction LR
        A --> B --> C --> D;
    end

    subgraph "Обучение и Оценка"
        direction TB
        E --> F & G;
        F --> H --> I;
        G & I --> J --> K;
        I --> L;
        I & G --> M --> N;
    end
```

## Заключение

В этой главе мы прошли весь путь от подготовленных признаков до работающей модели машинного обучения:

*   Мы поняли **основные концепции**: признаки, целевая переменная, модель, обучение, тест, оценка, гиперпараметры.
*   Мы подготовили **данные для модели**: выбрали нужные столбцы, создали "дельта"-признаки, разделили данные на обучающую и тестовую выборки по времени и масштабировали их.
*   Мы **обучили модель Логистической Регрессии** (`SGDClassifier`), используя `RandomizedSearchCV` для поиска оптимального гиперпараметра `alpha`.
*   Мы **оценили качество** модели на тестовых данных с помощью различных метрик (Accuracy, Log Loss, ROC AUC, Classification Report).
*   Мы научились **интерпретировать** модель, анализируя веса признаков (коэффициенты), чтобы понять, какие факторы наиболее важны для прогноза.
*   Мы получили **прогнозы** от модели в виде **вероятностей** победы для каждого игрока в тестовых матчах.

Теперь у нас есть инструмент, который может анализировать характеристики предстоящего матча и выдавать оценку шансов каждого игрока на победу. В следующей, заключительной главе, мы используем эти вероятности для построения и симуляции различных стратегий ставок, чтобы проверить, можно ли использовать нашу модель для получения прибыли.

**Далее:** [Глава 7: Симуляция ставок](07_симуляция_ставок_.html)

---